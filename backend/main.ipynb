{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-sxp1CfbM20xTzYUlEi2tT3BlbkFJhq11qNZDGC4AakfQOYkB\n"
     ]
    }
   ],
   "source": [
    "from helper import get_openai_api_key\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "print(OPENAI_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\"Useful for summarization questions related to MetaGPT\"),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\"Useful for retrieving specific context from the MetaGPT paper.\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to MetaGPT.\n",
      "\u001b[0mThe document discusses MetaGPT, a meta-programming framework that utilizes SOPs to enhance multi-agent systems based on LLMs. It outlines the development process involving various agents like Product Managers, Architects, Engineers, Project Managers, and QA Engineers. MetaGPT demonstrates superior performance in code generation tasks compared to other frameworks. The document provides insights into the software development lifecycle of a \"Drawing App\" using MetaGPT, highlighting the roles of different agents and the use of Python libraries for GUI creation. It also addresses limitations, ethical concerns, and challenges associated with MetaGPT while showcasing its capabilities in automating software development tasks efficiently.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: This choice is more relevant as it specifically mentions retrieving specific context, which is necessary for understanding how agents share information with other agents..\n",
      "\u001b[0mAgents share information with other agents by utilizing a shared message pool where they can publish structured messages and also subscribe to relevant messages based on their profiles. This shared message pool allows all agents to exchange messages directly, enabling them to access messages from other entities transparently. By storing information in this global message pool, agents can retrieve required information directly without the need to inquire about other agents and wait for their responses, thus enhancing communication efficiency.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How do agents share information with other agents?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_router_query_engine\n",
    "\n",
    "query_engine = get_router_query_engine(\"metagpt.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Ablation study results are specific context from the MetaGPT paper, so choice 2 is most relevant for retrieving this information..\n",
      "\u001b[0mThe ablation study results provide insights into the impact of removing certain components or features from a system or model. This analysis helps in understanding the contribution and significance of individual elements towards the overall performance or functionality of the system.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def mystery(x: int, y: int) -> int:\n",
    "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: mystery with args: {\"x\": 2, \"y\": 9}\n",
      "=== Function Output ===\n",
      "121\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "response = llm.predict_and_call(\n",
    "    [add_tool, mystery_tool],\n",
    "    \"Tell me the output of the mystery function on 2 and 9\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: metagpt.pdf\n",
      "file_path: metagpt.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16911937\n",
      "creation_date: 2024-05-18\n",
      "last_modified_date: 2024-05-17\n",
      "\n",
      "Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
      "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
      "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
      "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
      "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
      "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
      "5Nanjing University,6University of Pennsylvania,\n",
      "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
      "ABSTRACT\n",
      "Remarkable progress has been made on automated problem solving through so-\n",
      "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
      "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
      "complex tasks, however, are complicated through logic inconsistencies due to\n",
      "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
      "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
      "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
      "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
      "streamlined workflows, thus allowing agents with human-like domain expertise\n",
      "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
      "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
      "complex tasks into subtasks involving many agents working together. On col-\n",
      "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
      "solutions than previous chat-based multi-agent systems. Our project can be found\n",
      "at https://github.com/geekan/MetaGPT.\n",
      "1 I NTRODUCTION\n",
      "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
      "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
      "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
      "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
      "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
      "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
      "et al., 2023; Qian et al., 2023).\n",
      "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
      "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
      "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
      "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
      "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
      "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
      "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
      "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
      "(PRDs) using a standardized structure, to guide the developmental process.\n",
      "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
      "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
      "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
      "∗These authors contributed equally to this work.\n",
      "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts([{\"key\": \"page_label\", \"value\": \"2\"}]),\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What are some high-level results of MetaGPT?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some high-level results of MetaGPT include achieving a new state-of-the-art in code generation benchmarks with 85.9% and 87.7% in Pass@1, outperforming other popular frameworks like AutoGPT, LangChain, AgentVerse, and ChatDev. Additionally, MetaGPT demonstrates robustness and efficiency by achieving a 100% task completion rate in experimental evaluations, highlighting its effectiveness in handling higher levels of software complexity and offering extensive functionality.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-05-18', 'last_modified_date': '2024-05-17'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "\n",
    "\n",
    "def vector_query(query: str, page_numbers: List[str]) -> str:\n",
    "    \"\"\"Perform a vector search over an index.\n",
    "\n",
    "    query (str): the string query to be embedded.\n",
    "    page_numbers (List[str]): Filter by set of pages. Leave BLANK if we want to perform a vector search\n",
    "        over all pages. Otherwise, filter by the set of specified pages.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    metadata_dicts = [{\"key\": \"page_label\", \"value\": p} for p in page_numbers]\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts, condition=FilterCondition.OR\n",
    "        ),\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(name=\"vector_tool\", fn=vector_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"query\": \"high-level results of MetaGPT\", \"page_numbers\": [\"2\"]}\n",
      "=== Function Output ===\n",
      "MetaGPT achieves a new state-of-the-art (SoTA) in code generation benchmarks with 85.9% and 87.7% in Pass@1. It stands out in handling higher levels of software complexity and offering extensive functionality, demonstrating a 100% task completion rate in experimental evaluations.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool],\n",
    "    \"What are the high-level results of MetaGPT as described on page 2?\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-05-18', 'last_modified_date': '2024-05-17'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\"Useful if you want to get a summary of MetaGPT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"query\": \"MetaGPT comparisons with ChatDev\", \"page_numbers\": [\"8\"]}\n",
      "=== Function Output ===\n",
      "MetaGPT outperforms ChatDev on the SoftwareDev dataset in various aspects. For example, MetaGPT achieves a higher score in executability, takes less time for execution, requires more tokens but uses fewer tokens to generate one line of code compared to ChatDev. Additionally, MetaGPT demonstrates better performance in code statistics and human revision cost when compared to ChatDev.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool],\n",
    "    \"What are the MetaGPT comparisons with ChatDev described on page 8?\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-05-18', 'last_modified_date': '2024-05-17'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: summary_tool with args: {\"input\": \"The paper discusses the impact of climate change on biodiversity and ecosystems.\"}\n",
      "=== Function Output ===\n",
      "The paper does not discuss the impact of climate change on biodiversity and ecosystems.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \"What is a summary of the paper?\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "# this should be a utils function (in utils.py)\n",
    "\n",
    "\n",
    "def get_doc_tools(\n",
    "    file_path: str,\n",
    "    name: str,\n",
    ") -> str:\n",
    "    \"\"\"Get vector query and summary query tools from a document.\"\"\"\n",
    "\n",
    "    # load documents\n",
    "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "    splitter = SentenceSplitter(chunk_size=1024)\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    vector_index = VectorStoreIndex(nodes)\n",
    "\n",
    "    def vector_query(query: str, page_numbers: Optional[List[str]] = None) -> str:\n",
    "        \"\"\"Use to answer questions over the MetaGPT paper.\n",
    "\n",
    "        Useful if you have specific questions over the MetaGPT paper.\n",
    "        Always leave page_numbers as None UNLESS there is a specific page you want to search for.\n",
    "\n",
    "        Args:\n",
    "            query (str): the string query to be embedded.\n",
    "            page_numbers (Optional[List[str]]): Filter by set of pages. Leave as NONE\n",
    "                if we want to perform a vector search\n",
    "                over all pages. Otherwise, filter by the set of specified pages.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        page_numbers = page_numbers or []\n",
    "        metadata_dicts = [{\"key\": \"page_label\", \"value\": p} for p in page_numbers]\n",
    "\n",
    "        query_engine = vector_index.as_query_engine(\n",
    "            similarity_top_k=2,\n",
    "            filters=MetadataFilters.from_dicts(\n",
    "                metadata_dicts, condition=FilterCondition.OR\n",
    "            ),\n",
    "        )\n",
    "        response = query_engine.query(query)\n",
    "        return response\n",
    "\n",
    "    vector_query_tool = FunctionTool.from_defaults(\n",
    "        name=f\"vector_tool_{name}\", fn=vector_query\n",
    "    )\n",
    "\n",
    "    summary_index = SummaryIndex(nodes)\n",
    "    summary_query_engine = summary_index.as_query_engine(\n",
    "        response_mode=\"tree_summarize\",\n",
    "        use_async=True,\n",
    "    )\n",
    "    summary_tool = QueryEngineTool.from_defaults(\n",
    "        name=f\"summary_tool_{name}\",\n",
    "        query_engine=summary_query_engine,\n",
    "        description=(\n",
    "            \"Use ONLY IF you want to get a holistic summary of MetaGPT. \"\n",
    "            \"Do NOT use if you have specific questions over MetaGPT.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return vector_query_tool, summary_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_tool, summary_tool = get_doc_tools(\"metagpt.pdf\", \"metagpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/alexanderphan_1/Developer/ilya-papers/backend', '/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python312.zip', '/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12', '/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/lib-dynload', '', '/Users/alexanderphan_1/Developer/ilya-papers/backend/venv/lib/python3.12/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [vector_tool, summary_tool], llm=llm, verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"agent roles in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "The agent roles in MetaGPT include the Product Manager, Architect, Project Manager, Engineer, and QA Engineer. The Product Manager is responsible for creating the Product Requirement Document and conducting competitive analysis. The Architect is in charge of designing technical specifications and system architecture. The Project Manager breaks down the project into tasks for the team to execute. Engineers implement the code based on the provided specifications. Lastly, the QA Engineer is responsible for generating unit tests and ensuring the software's quality. Each role contributes significantly to the collaborative software development process within MetaGPT.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"communication between agent roles in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "The communication between agent roles in MetaGPT is structured and well-defined, with each agent having specific responsibilities and tasks assigned to them based on their expertise. The Product Manager generates the Product Requirement Document (PRD) containing goals, user stories, competitive analysis, and requirement analysis. The Architect then designs the system architecture and interface definitions based on the PRD. The Project Manager breaks down the project into tasks, and the Engineer implements the code based on the technical specifications provided by the Architect. The QA Engineer reviews the code and creates unit tests to ensure high-quality software. This structured communication and workflow among different agent roles in MetaGPT help streamline the software development process and ensure efficient collaboration.\n",
      "=== LLM Response ===\n",
      "In MetaGPT, the agent roles include the Product Manager, Architect, Project Manager, Engineer, and QA Engineer. Each role has specific responsibilities in the software development process. The Product Manager creates the Product Requirement Document, the Architect designs the technical specifications, the Project Manager breaks down tasks, Engineers implement the code, and the QA Engineer ensures software quality.\n",
      "\n",
      "Communication between these agent roles is structured and well-defined. The Product Manager creates the PRD, the Architect designs the system architecture, the Project Manager assigns tasks, Engineers implement code based on specifications, and the QA Engineer reviews code and creates unit tests. This structured communication ensures efficient collaboration and a streamlined software development process in MetaGPT.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Tell me about the agent roles in MetaGPT, \"\n",
    "    \"and then how they communicate with each other.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: metagpt.pdf\n",
      "file_path: metagpt.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16911937\n",
      "creation_date: 2024-05-18\n",
      "last_modified_date: 2024-05-17\n",
      "\n",
      "Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
      "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
      "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
      "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
      "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
      "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
      "5Nanjing University,6University of Pennsylvania,\n",
      "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
      "ABSTRACT\n",
      "Remarkable progress has been made on automated problem solving through so-\n",
      "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
      "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
      "complex tasks, however, are complicated through logic inconsistencies due to\n",
      "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
      "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
      "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
      "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
      "streamlined workflows, thus allowing agents with human-like domain expertise\n",
      "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
      "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
      "complex tasks into subtasks involving many agents working together. On col-\n",
      "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
      "solutions than previous chat-based multi-agent systems. Our project can be found\n",
      "at https://github.com/geekan/MetaGPT.\n",
      "1 I NTRODUCTION\n",
      "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
      "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
      "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
      "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
      "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
      "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
      "et al., 2023; Qian et al., 2023).\n",
      "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
      "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
      "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
      "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
      "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
      "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
      "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
      "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
      "(PRDs) using a standardized structure, to guide the developmental process.\n",
      "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
      "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
      "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
      "∗These authors contributed equally to this work.\n",
      "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the evaluation datasets used.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"evaluation datasets used in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "The evaluation datasets used in MetaGPT include HumanEval, MBPP, and a self-generated SoftwareDev dataset. The HumanEval dataset consists of 164 handwritten programming tasks, while the MBPP dataset consists of 427 Python tasks. The SoftwareDev dataset contains 70 representative software development tasks covering various scopes such as mini-games, image processing algorithms, and data visualization.\n",
      "=== LLM Response ===\n",
      "The evaluation datasets used in MetaGPT include HumanEval, MBPP, and a self-generated SoftwareDev dataset. HumanEval comprises 164 handwritten programming tasks, MBPP consists of 427 Python tasks, and the SoftwareDev dataset includes 70 representative software development tasks covering mini-games, image processing algorithms, and data visualization.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Tell me about the evaluation datasets used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me the results over one of the above datasets.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_metagpt with args: {\"query\": \"results over the HumanEval dataset\", \"page_numbers\": [\"7\"]}\n",
      "=== Function Output ===\n",
      "MetaGPT achieved 85.9% and 87.7% results over the HumanEval dataset.\n",
      "=== LLM Response ===\n",
      "MetaGPT achieved impressive results of 85.9% and 87.7% over the HumanEval dataset.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Tell me the results over one of the above datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [vector_tool, summary_tool], llm=llm, verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = agent.create_task(\n",
    "    \"Tell me about the agent roles in MetaGPT, \"\n",
    "    \"and then how they communicate with each other.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"agent roles in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "The agent roles in MetaGPT include the Product Manager, Architect, Project Manager, Engineer, and QA Engineer. The Product Manager is responsible for creating the Product Requirement Document (PRD). The Architect designs technical specifications and system architecture diagrams. The Project Manager breaks down the project into tasks and assigns them to Engineers. Engineers implement development tasks based on the assigned tasks. The QA Engineer generates unit test code, reviews the code output, and ensures high-quality software by identifying and fixing bugs.\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(task.task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num completed for task df446033-db22-4214-96da-f3e599959822: 1\n",
      "The agent roles in MetaGPT include the Product Manager, Architect, Project Manager, Engineer, and QA Engineer. The Product Manager is responsible for creating the Product Requirement Document (PRD). The Architect designs technical specifications and system architecture diagrams. The Project Manager breaks down the project into tasks and assigns them to Engineers. Engineers implement development tasks based on the assigned tasks. The QA Engineer generates unit test code, reviews the code output, and ensures high-quality software by identifying and fixing bugs.\n"
     ]
    }
   ],
   "source": [
    "completed_steps = agent.get_completed_steps(task.task_id)\n",
    "print(f\"Num completed for task {task.task_id}: {len(completed_steps)}\")\n",
    "print(completed_steps[0].output.sources[0].raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num upcoming steps for task df446033-db22-4214-96da-f3e599959822: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskStep(task_id='df446033-db22-4214-96da-f3e599959822', step_id='2fb681d5-c6b5-467d-ba0f-4a8e898c577e', input=None, step_state={}, next_steps={}, prev_steps={}, is_ready=True)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upcoming_steps = agent.get_upcoming_steps(task.task_id)\n",
    "print(f\"Num upcoming steps for task {task.task_id}: {len(upcoming_steps)}\")\n",
    "upcoming_steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What about how agents share information?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"how agents share information in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "Agents in MetaGPT share information through a shared message pool and a subscription mechanism. The shared message pool allows agents to exchange structured messages directly, facilitating transparent communication. Agents can subscribe to relevant messages based on their profiles, ensuring efficient communication and information exchange within the system. This structured communication interface helps prevent information overload and enhances communication efficiency among the agents.\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(\n",
    "    task.task_id, input=\"What about how agents share information?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Response ===\n",
      "In MetaGPT, agents share information through a shared message pool and a subscription mechanism. The shared message pool enables agents to exchange structured messages directly, facilitating transparent communication. Agents can subscribe to relevant messages based on their profiles, ensuring efficient communication and information exchange within the system. This structured communication interface helps prevent information overload and enhances communication efficiency among the agents.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(task.task_id)\n",
    "print(step_output.is_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.finalize_response(task.task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: In MetaGPT, agents share information through a shared message pool and a subscription mechanism. The shared message pool enables agents to exchange structured messages directly, facilitating transparent communication. Agents can subscribe to relevant messages based on their profiles, ensuring efficient communication and information exchange within the system. This structured communication interface helps prevent information overload and enhances communication efficiency among the agents.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://nlp.seas.harvard.edu/annotated-transformer/\",\n",
    "    \"https://scottaaronson.blog/?p=762\",\n",
    "    \"https://karpathy.github.io/2015/05/21/rnn-effectiveness/\",\n",
    "    \"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\",\n",
    "    \"https://cs231n.github.io/\",\n",
    "    \"https://arxiv.org/pdf/1409.2329.pdf\",\n",
    "    \"https://www.cs.toronto.edu/~hinton/absps/colt93.pdf\",\n",
    "    \"https://arxiv.org/pdf/1506.03134.pdf\",\n",
    "    \"https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\",\n",
    "    \"https://arxiv.org/pdf/1511.06391.pdf\",\n",
    "    \"https://arxiv.org/pdf/1811.06965.pdf\",\n",
    "    \"https://arxiv.org/pdf/1512.03385.pdf\",\n",
    "    \"https://arxiv.org/pdf/1511.07122.pdf\",\n",
    "    \"https://arxiv.org/pdf/1704.01212.pdf\",\n",
    "    \"https://arxiv.org/pdf/1706.03762.pdf\",\n",
    "    \"https://arxiv.org/pdf/1409.0473.pdf\",\n",
    "    \"https://arxiv.org/pdf/1603.05027.pdf\",\n",
    "    \"https://arxiv.org/pdf/1706.01427.pdf\",\n",
    "    \"https://arxiv.org/pdf/1611.02731.pdf\",\n",
    "    \"https://arxiv.org/pdf/1806.01822.pdf\",\n",
    "    \"https://arxiv.org/pdf/1405.6903.pdf\",\n",
    "    \"https://arxiv.org/pdf/1410.5401.pdf\",\n",
    "    \"https://arxiv.org/pdf/1512.02595.pdf\",\n",
    "    \"https://arxiv.org/pdf/2001.08361.pdf\",\n",
    "    \"https://arxiv.org/pdf/math/0406077.pdf\",\n",
    "    \"https://www.vetta.org/documents/Machine_Super_Intelligence.pdf\",\n",
    "    \"https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf\",\n",
    "]\n",
    "\n",
    "# in a subdirectory called papers\n",
    "papers = [\n",
    "    \"papers/annotated_transformer.pdf\",\n",
    "    \"papers/first_law_of_thermodynamics.html\",\n",
    "    \"papers/karpathy_rnn_effectiveness.html\",\n",
    "    \"papers/colah_understanding_lstms.html\",\n",
    "    \"papers/cs231n_2015_rnn_regularization.pdf\",\n",
    "    \"papers/keeping_nn_simple_hinton.pdf\",\n",
    "    \"papers/pointer_networks.pdf\",\n",
    "    \"papers/imagenet_classification.pdf\",\n",
    "    \"papers/order_matters_s_to_s.pdf\",\n",
    "    \"papers/GPipe.pdf\",\n",
    "    \"papers/deep_residual_learning_image_recognition.pdf\",\n",
    "    \"papers/multi_scale_context_aggregation.pdf\",\n",
    "    \"papers/nerual_quantum_chemistry.pdf\",\n",
    "    \"papers/attention_is_all_you_need.pdf\",\n",
    "    \"papers/neural_machine_translation.pdf\",\n",
    "    \"papers/identity_mappings_deep_residual_networks.pdf\",\n",
    "    \"papers/simple_nn_module.pdf\",\n",
    "    \"papers/variational_lossy_autoencoder.pdf\",\n",
    "    \"papers/relational_rnns.pdf\",\n",
    "    \"papers/quantifying_rise_fall_complexity.pdf\",\n",
    "    \"papers/neural_turing_machines.pdf\",\n",
    "    \"papers/deep_speech_2.pdf\",\n",
    "    \"papers/scaling_laws_for_neural_llms.pdf\",\n",
    "    \"papers/intro_minimum_description_length_principle.pdf\",\n",
    "    \"papers/machine_super_intelligence.pdf\",\n",
    "    \"papers/kolmogorov_complexity.pdf\",\n",
    "    \"papers/cnns_for_visual_recognition.html\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import get_doc_tools\n",
    "# should be a utils function (utils.py)\n",
    "\n",
    "\n",
    "def get_doc_tools(\n",
    "    file_path: str,\n",
    "    name: str,\n",
    ") -> str:\n",
    "    \"\"\"Get vector query and summary query tools from a document.\"\"\"\n",
    "\n",
    "    # load documents\n",
    "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "    splitter = SentenceSplitter(chunk_size=1024)\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    vector_index = VectorStoreIndex(nodes)\n",
    "\n",
    "    def vector_query(query: str, page_numbers: Optional[List[str]] = None) -> str:\n",
    "        \"\"\"Use to answer questions over the MetaGPT paper.\n",
    "\n",
    "        Useful if you have specific questions over the MetaGPT paper.\n",
    "        Always leave page_numbers as None UNLESS there is a specific page you want to search for.\n",
    "\n",
    "        Args:\n",
    "            query (str): the string query to be embedded.\n",
    "            page_numbers (Optional[List[str]]): Filter by set of pages. Leave as NONE\n",
    "                if we want to perform a vector search\n",
    "                over all pages. Otherwise, filter by the set of specified pages.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        page_numbers = page_numbers or []\n",
    "        metadata_dicts = [{\"key\": \"page_label\", \"value\": p} for p in page_numbers]\n",
    "\n",
    "        query_engine = vector_index.as_query_engine(\n",
    "            similarity_top_k=2,\n",
    "            filters=MetadataFilters.from_dicts(\n",
    "                metadata_dicts, condition=FilterCondition.OR\n",
    "            ),\n",
    "        )\n",
    "        response = query_engine.query(query)\n",
    "        return response\n",
    "\n",
    "    vector_query_tool = FunctionTool.from_defaults(\n",
    "        name=f\"vector_tool_{name}\", fn=vector_query\n",
    "    )\n",
    "\n",
    "    summary_index = SummaryIndex(nodes)\n",
    "    summary_query_engine = summary_index.as_query_engine(\n",
    "        response_mode=\"tree_summarize\",\n",
    "        use_async=True,\n",
    "    )\n",
    "    summary_tool = QueryEngineTool.from_defaults(\n",
    "        name=f\"summary_tool_{name}\",\n",
    "        query_engine=summary_query_engine,\n",
    "        description=(\n",
    "            \"Use ONLY IF you want to get a holistic summary of MetaGPT. \"\n",
    "            \"Do NOT use if you have specific questions over MetaGPT.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return vector_query_tool, summary_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: papers/annotated_transformer.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file papers/annotated_transformer.pdf with error: RetryError[<Future at 0x29543c3b0 state=finished raised PdfStreamError>]. Skipping...\n",
      "Getting tools for paper: papers/first_law_of_thermodynamics.html\n",
      "Getting tools for paper: papers/karpathy_rnn_effectiveness.html\n",
      "Getting tools for paper: papers/colah_understanding_lstms.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: papers/cs231n_2015_rnn_regularization.pdf\n",
      "Failed to load file papers/cs231n_2015_rnn_regularization.pdf with error: RetryError[<Future at 0x29e4f1550 state=finished raised PdfStreamError>]. Skipping...\n",
      "Getting tools for paper: papers/keeping_nn_simple_hinton.pdf\n",
      "Getting tools for paper: papers/pointer_networks.pdf\n",
      "Getting tools for paper: papers/imagenet_classification.pdf\n",
      "Getting tools for paper: papers/order_matters_s_to_s.pdf\n",
      "Getting tools for paper: papers/GPipe.pdf\n",
      "Getting tools for paper: papers/deep_residual_learning_image_recognition.pdf\n",
      "Getting tools for paper: papers/multi_scale_context_aggregation.pdf\n",
      "Getting tools for paper: papers/nerual_quantum_chemistry.pdf\n",
      "Getting tools for paper: papers/attention_is_all_you_need.pdf\n",
      "Getting tools for paper: papers/neural_machine_translation.pdf\n",
      "Getting tools for paper: papers/identity_mappings_deep_residual_networks.pdf\n",
      "Getting tools for paper: papers/simple_nn_module.pdf\n",
      "Getting tools for paper: papers/variational_lossy_autoencoder.pdf\n",
      "Getting tools for paper: papers/relational_rnns.pdf\n",
      "Getting tools for paper: papers/quantifying_rise_fall_complexity.pdf\n",
      "Getting tools for paper: papers/neural_turing_machines.pdf\n",
      "Getting tools for paper: papers/deep_speech_2.pdf\n",
      "Getting tools for paper: papers/scaling_laws_for_neural_llms.pdf\n",
      "Getting tools for paper: papers/intro_minimum_description_length_principle.pdf\n",
      "Getting tools for paper: papers/machine_super_intelligence.pdf\n",
      "Getting tools for paper: papers/kolmogorov_complexity.pdf\n",
      "Getting tools for paper: papers/cnns_for_visual_recognition.html\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "paper_to_tools_dict = {}\n",
    "for paper in papers:\n",
    "    print(f\"Getting tools for paper: {paper}\")\n",
    "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
    "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    initial_tools, llm=llm, verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the evaluation dataset used in rnns and then tell me about the evaluation results\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_relational_rnns with args: {\"query\": \"evaluation dataset\"}\n",
      "=== Function Output ===\n",
      "Semi-supervised variational autoencoders for sequence classification.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_relational_rnns with args: {\"query\": \"evaluation results\"}\n",
      "=== Function Output ===\n",
      "VLAE models with AF prior and PixelCNN conditional achieved new state-of-the-art results on statically binarized MNIST. Additionally, on dynamically binarized MNIST, VLAE outperformed other models in terms of test NLL. On the OMNIGLOT dataset, VLAE showed improved performance compared to other models, especially when fine-tuned. Lastly, on the Caltech-101 Silhouettes dataset, VLAE demonstrated the lowest test NLL among the listed models.\n",
      "=== LLM Response ===\n",
      "The evaluation dataset used in Relational RNNs is the Semi-supervised variational autoencoders for sequence classification. \n",
      "\n",
      "The evaluation results of Relational RNNs show that VLAE models with AF prior and PixelCNN conditional achieved new state-of-the-art results on statically binarized MNIST. Additionally, on dynamically binarized MNIST, VLAE outperformed other models in terms of test NLL. On the OMNIGLOT dataset, VLAE showed improved performance compared to other models, especially when fine-tuned. Lastly, on the Caltech-101 Silhouettes dataset, VLAE demonstrated the lowest test NLL among the listed models.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Tell me about the evaluation dataset used in rnns \"\n",
    "    \"and then tell me about the evaluation results\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: papers/annotated_transformer.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file papers/annotated_transformer.pdf with error: RetryError[<Future at 0x2a2519f10 state=finished raised PdfStreamError>]. Skipping...\n",
      "Getting tools for paper: papers/first_law_of_thermodynamics.html\n",
      "Getting tools for paper: papers/karpathy_rnn_effectiveness.html\n",
      "Getting tools for paper: papers/colah_understanding_lstms.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: papers/cs231n_2015_rnn_regularization.pdf\n",
      "Failed to load file papers/cs231n_2015_rnn_regularization.pdf with error: RetryError[<Future at 0x2a38e53d0 state=finished raised PdfStreamError>]. Skipping...\n",
      "Getting tools for paper: papers/keeping_nn_simple_hinton.pdf\n",
      "Getting tools for paper: papers/pointer_networks.pdf\n",
      "Getting tools for paper: papers/imagenet_classification.pdf\n",
      "Getting tools for paper: papers/order_matters_s_to_s.pdf\n",
      "Getting tools for paper: papers/GPipe.pdf\n",
      "Getting tools for paper: papers/deep_residual_learning_image_recognition.pdf\n",
      "Getting tools for paper: papers/multi_scale_context_aggregation.pdf\n",
      "Getting tools for paper: papers/nerual_quantum_chemistry.pdf\n",
      "Getting tools for paper: papers/attention_is_all_you_need.pdf\n",
      "Getting tools for paper: papers/neural_machine_translation.pdf\n",
      "Getting tools for paper: papers/identity_mappings_deep_residual_networks.pdf\n",
      "Getting tools for paper: papers/simple_nn_module.pdf\n",
      "Getting tools for paper: papers/variational_lossy_autoencoder.pdf\n",
      "Getting tools for paper: papers/relational_rnns.pdf\n",
      "Getting tools for paper: papers/quantifying_rise_fall_complexity.pdf\n",
      "Getting tools for paper: papers/neural_turing_machines.pdf\n",
      "Getting tools for paper: papers/deep_speech_2.pdf\n",
      "Getting tools for paper: papers/scaling_laws_for_neural_llms.pdf\n",
      "Getting tools for paper: papers/intro_minimum_description_length_principle.pdf\n",
      "Getting tools for paper: papers/machine_super_intelligence.pdf\n",
      "Getting tools for paper: papers/kolmogorov_complexity.pdf\n",
      "Getting tools for paper: papers/cnns_for_visual_recognition.html\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "paper_to_tools_dict = {}\n",
    "for paper in papers:\n",
    "    print(f\"Getting tools for paper: {paper}\")\n",
    "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
    "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an \"object\" index and retriever over these tools\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = obj_retriever.retrieve(\n",
    "    \"Tell me about the eval dataset used in MetaGPT and SWE-Bench\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMetadata(description='Use ONLY IF you want to get a holistic summary of MetaGPT. Do NOT use if you have specific questions over MetaGPT.', name='summary_tool_deep_speech_2', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[2].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_retriever,\n",
    "    llm=llm,\n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given papers.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True,\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Explain RNNs for me\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_cs231n_2015_rnn_regularization with args: {\"input\": \"Recurrent Neural Networks (RNNs) are a type of neural network designed to handle sequential data. Unlike traditional feedforward neural networks, RNNs have connections that form a directed cycle, allowing them to exhibit dynamic temporal behavior. RNNs are well-suited for tasks such as language modeling, speech recognition, and time series prediction. However, they can suffer from issues like vanishing gradients, which can make it challenging for them to learn long-range dependencies. Various techniques like Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs) have been developed to address these challenges and improve the effectiveness of RNNs in capturing long-term dependencies in sequential data.\"}\n",
      "=== Function Output ===\n",
      "Empty Response\n",
      "=== LLM Response ===\n",
      "RNNs (Recurrent Neural Networks) are a type of neural network specifically designed to handle sequential data. They differ from traditional feedforward neural networks by having connections that form a directed cycle, enabling them to exhibit dynamic temporal behavior. RNNs are commonly used for tasks such as language modeling, speech recognition, and time series prediction. However, they face challenges like vanishing gradients, which can hinder their ability to learn long-range dependencies. To overcome these issues, techniques like Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs) have been developed to enhance the effectiveness of RNNs in capturing long-term dependencies in sequential data.\n",
      "assistant: RNNs (Recurrent Neural Networks) are a type of neural network specifically designed to handle sequential data. They differ from traditional feedforward neural networks by having connections that form a directed cycle, enabling them to exhibit dynamic temporal behavior. RNNs are commonly used for tasks such as language modeling, speech recognition, and time series prediction. However, they face challenges like vanishing gradients, which can hinder their ability to learn long-range dependencies. To overcome these issues, techniques like Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs) have been developed to enhance the effectiveness of RNNs in capturing long-term dependencies in sequential data.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Explain RNNs for me\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: give me a list of papers that talk about lstms\n",
      "=== LLM Response ===\n",
      "Sure, I can help with that. Let me find a list of papers that talk about LSTMs for you.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_colah_understanding_lstms with args: {\"query\": \"papers about LSTMs\"}\n",
      "=== Function Output ===\n",
      "Kalchbrenner, Gregor, Chung, Bayer & Osendorfer are authors who have worked on papers related to LSTMs.\n",
      "=== LLM Response ===\n",
      "I found that authors like Kalchbrenner, Gregor, Chung, Bayer, and Osendorfer have worked on papers related to LSTMs. If you would like more specific information or details about these papers, please let me know.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    # \"Compare and contrast the LoRA papers (LongLoRA, LoftQ). \"\n",
    "    # \"Analyze the approach in each paper first. \"\n",
    "    \"give me a list of papers that talk about lstms\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
